{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Project Summary  \n",
        "\n",
        "This project is part of the **Deep Learning Practice (DLP)** course, focusing on **Image Classification** using deep learning models. The dataset consists of images from the world of **flora and fauna**, and the goal is to build a model that classifies these images with the **best F1 score**.  \n",
        "\n",
        "The final model's performance will be evaluated based on its classification accuracy."
      ],
      "metadata": {
        "id": "GL0LCmx79ndY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Installation**"
      ],
      "metadata": {
        "id": "aRuOy8edgX-Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzAvZFjpJawC"
      },
      "outputs": [],
      "source": [
        "# Evaluating machine learning models on various metrics\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch  # PyTorch library for tensor computations and deep learning\n",
        "import torchvision.transforms as transforms  # Transformations for image preprocessing\n",
        "from torchvision.datasets import ImageFolder  # Dataset loader for image classification\n",
        "from torchvision.models import vgg19_bn, resnet18  # Pretrained models for feature extraction and classification\n",
        "from torch.utils.data import DataLoader  # DataLoader for batching and shuffling datasets\n",
        "import torch.nn.functional as F  # Functional interface for PyTorch operations\n",
        "import os  # OS module for handling file paths and directories\n",
        "from torch.utils.data import DataLoader, random_split  # Additional data utilities for dataset splitting\n",
        "import torch.nn as nn  # Neural network module for defining model architectures\n",
        "import torch.optim as optim  # Optimization algorithms for training models\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification, TrainingArguments, Trainer  # Hugging Face Transformers for image classification\n",
        "import evaluate  # Library for evaluation metrics\n",
        "\n",
        "from datasets import load_dataset, ClassLabel  # Dataset utilities for handling and processing datasets\n",
        "from PIL import Image  # Image handling and manipulation"
      ],
      "metadata": {
        "id": "CkZvWXhFJ1gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device to GPU if available, otherwise fallback to CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "LWcIN6kGJ7YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Pre-processing**"
      ],
      "metadata": {
        "id": "Cyfr1R4MgdFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset from disk (Modify paths accordingly)\n",
        "dataset_path = \"/kaggle/input/deep-learning-practice-week-9-image-c-lassifica\"\n",
        "dataset = load_dataset(\"imagefolder\", data_dir=dataset_path, split={\"train\": \"train\", \"test\": \"test\"})"
      ],
      "metadata": {
        "id": "mGZ-_ugbJ97n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training and testing sets\n",
        "train_dataset = dataset['train']\n",
        "test_dataset = dataset['test']"
      ],
      "metadata": {
        "id": "PyG7KvssKEvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset again for extracting class names\n",
        "dataset_path = \"/kaggle/input/deep-learning-practice-week-9-image-c-lassifica/train\"\n",
        "dataset = load_dataset(\"imagefolder\", data_dir=dataset_path)\n",
        "\n",
        "# Extract class names (folder names) in sorted order\n",
        "class_names = sorted(dataset[\"train\"].features[\"label\"].names)\n",
        "\n",
        "# Create a ClassLabel mapping\n",
        "class_label = ClassLabel(names=class_names)\n",
        "\n",
        "# Assign labels based on the dataset's existing 'label' field\n",
        "def add_labels(example):\n",
        "    example[\"label\"] = class_label.str2int(class_names[example[\"label\"]])  # Map label index to integer\n",
        "    return example"
      ],
      "metadata": {
        "id": "qvSvp1WIKGQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the 'add_labels' function to the 'train' dataset\n",
        "train_dataset = dataset[\"train\"].map(add_labels)\n",
        "\n",
        "# Shuffle the training dataset with a fixed seed for reproducibility\n",
        "train_dataset.shuffle(seed=42)\n",
        "\n",
        "# Display the first element from the 'test' dataset\n",
        "test_dataset[0]"
      ],
      "metadata": {
        "id": "D39mpTizKId4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Initialization**"
      ],
      "metadata": {
        "id": "SlVvYPPcgjr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the model checkpoint for the Vision Transformer (ViT) pre-trained model\n",
        "model_checkpoint = \"google/vit-base-patch16-224-in21k\"  # Vision Transformer (ViT)\n",
        "\n",
        "# Load the image processor for the Vision Transformer model to handle image preprocessing\n",
        "processor = AutoImageProcessor.from_pretrained(model_checkpoint)\n",
        "\n",
        "# Load the pre-trained model for image classification, specifying the number of output labels (adjust this for your dataset)\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    model_checkpoint, num_labels=10  # Adjust for your dataset\n",
        ").to(device)  # Move the model to the specified device (CPU/GPU)"
      ],
      "metadata": {
        "id": "a5wP7LRzKpGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Transformation**"
      ],
      "metadata": {
        "id": "B55KMpgbgwUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to transform the images in the dataset\n",
        "def transform_images(example):\n",
        "    image = example[\"image\"]\n",
        "\n",
        "    # Ensure the image is in PIL format if it's not already\n",
        "    if not isinstance(image, Image.Image):\n",
        "        image = Image.fromarray(image)\n",
        "\n",
        "    # Convert grayscale images to RGB format (3-channel)\n",
        "    if image.mode != \"RGB\":\n",
        "        image = image.convert(\"RGB\")\n",
        "\n",
        "    # Process the image into tensor format using the image processor\n",
        "    # 'squeeze(0)' is used to remove the batch dimension, so the shape is (C, H, W)\n",
        "    pixel_values = processor(image, return_tensors=\"pt\")[\"pixel_values\"].squeeze(0)  # Shape: (C, H, W)\n",
        "\n",
        "    # Add the processed image as 'pixel_values' to the example dictionary\n",
        "    example[\"pixel_values\"] = pixel_values\n",
        "    return example\n",
        "\n",
        "# Apply the 'transform_images' function to the training dataset\n",
        "# 'remove_columns=[\"image\"]' removes the original image column from the dataset after transformation\n",
        "train_dataset = train_dataset.map(transform_images, remove_columns=[\"image\"])"
      ],
      "metadata": {
        "id": "i2SCl7OKKrxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Splitting**"
      ],
      "metadata": {
        "id": "GpKlOBe_g4c8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and validation sets with 80% for training and 20% for validation\n",
        "train_test_split = train_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "# Extract the new training and validation datasets from the split\n",
        "train_dataset = train_test_split[\"train\"]\n",
        "val_dataset = train_test_split[\"test\"]\n"
      ],
      "metadata": {
        "id": "87bfcJgWKtNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Evaluation**"
      ],
      "metadata": {
        "id": "QpoUtlhDg-im"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the F1 Score metric to evaluate model performance\n",
        "metric = evaluate.load(\"f1\")\n",
        "# Display the contents of the training dataset\n",
        "print(train_dataset)"
      ],
      "metadata": {
        "id": "hAObG6iwKwxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function to compute metrics during evaluation\n",
        "def compute_metrics(eval_pred):\n",
        "    # Unpack the logits (model's raw predictions) and labels (true labels)\n",
        "    logits, labels = eval_pred\n",
        "\n",
        "    # Convert logits to predicted class labels by taking the argmax along the last dimension (for classification)\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Compute and return the F1 score using the 'metric' object, with macro averaging\n",
        "    return metric.compute(predictions=predictions, references=labels, average=\"macro\")"
      ],
      "metadata": {
        "id": "fTEC8g_PK1hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Training**"
      ],
      "metadata": {
        "id": "ALtbqcCFhJdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up training arguments using the TrainingArguments class\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",  # Directory to save the model and results\n",
        "    evaluation_strategy=\"epoch\",  # Evaluate the model at the end of each epoch\n",
        "    save_strategy=\"epoch\",  # Save the model checkpoint at the end of each epoch\n",
        "    learning_rate=5e-5,  # Set the learning rate for the optimizer\n",
        "    per_device_train_batch_size=8,  # Batch size per device for training\n",
        "    per_device_eval_batch_size=8,  # Batch size per device for evaluation\n",
        "    num_train_epochs=2,  # Number of epochs to train the model\n",
        "    weight_decay=0.01,  # Weight decay for regularization to prevent overfitting\n",
        "    metric_for_best_model=\"f1\",  # Metric used to select the best model during training\n",
        "    load_best_model_at_end=True,  # Load the best model after training based on the evaluation metric\n",
        "    report_to=\"none\"  # Disable reporting to external platforms like TensorBoard or Weights & Biases\n",
        ")"
      ],
      "metadata": {
        "id": "KFv2h23DK6OH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Trainer, which will handle the training and evaluation process\n",
        "trainer = Trainer(\n",
        "    model=model,  # The model to be trained\n",
        "    args=training_args,  # The training arguments defined earlier (like learning rate, batch size, etc.)\n",
        "    train_dataset=train_dataset,  # The training dataset\n",
        "    eval_dataset=val_dataset,  # The validation dataset\n",
        "    tokenizer=processor,  # The processor used for tokenizing and processing the images\n",
        "    compute_metrics=compute_metrics  # The function to compute evaluation metrics (e.g., F1 score)\n",
        ")"
      ],
      "metadata": {
        "id": "OK3tOH2kK_Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start the training process using the defined Trainer object\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "JFxJ3b7ELANw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the 'transform_images' function to the test dataset to process images\n",
        "# 'remove_columns=[\"image\"]' removes the original image column after transformation\n",
        "test_dataset = test_dataset.map(transform_images, remove_columns=[\"image\"])"
      ],
      "metadata": {
        "id": "5LjS0F-JLCsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the trainer to make predictions on the test dataset\n",
        "predictions = trainer.predict(test_dataset)\n",
        "\n",
        "# Get the predicted class labels by taking the argmax of the model's raw predictions\n",
        "# This will convert logits (raw outputs) to predicted class indices\n",
        "test_preds = np.argmax(predictions.predictions, axis=-1)"
      ],
      "metadata": {
        "id": "2uKDK1mOLG0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory where the test images are stored\n",
        "image_dir = \"/kaggle/input/deep-learning-practice-week-9-image-c-lassifica/test\"\n",
        "\n",
        "# Get a sorted list of image file names (without extensions) from the specified directory\n",
        "# This assumes that the images are in \".jpg\" format and that the files are named with a consistent format\n",
        "test_image_ids = [os.path.splitext(f)[0] for f in sorted(os.listdir(image_dir)) if f.endswith(\".jpg\")]"
      ],
      "metadata": {
        "id": "o71zagvaLKJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Submission**"
      ],
      "metadata": {
        "id": "9LVmfLeBhaym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame to store the image IDs and their corresponding predicted labels\n",
        "submission_df = pd.DataFrame({\"Image_ID\": test_image_ids, \"Label\": test_preds})\n",
        "\n",
        "# Save the DataFrame to a CSV file, without including the index column\n",
        "submission_file = \"/kaggle/working/submission.csv\"\n",
        "submission_df.to_csv(submission_file, index=False)\n",
        "\n",
        "# Print the file path where the submission has been saved\n",
        "print(f\"Submission file saved: {submission_file}\")"
      ],
      "metadata": {
        "id": "YQyWwetSLRAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview the first few rows of the submission DataFrame\n",
        "submission_df.head()"
      ],
      "metadata": {
        "id": "s1dcYNA4LUTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv(\"/kaggle/working/submission.csv\")\n",
        "\n",
        "# Preview the first 10 rows of the DataFrame\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "E2iqzIhELXcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the 'submission.csv' file exists in the specified path and print the result\n",
        "print(os.path.exists(\"/kaggle/working/submission.csv\"))"
      ],
      "metadata": {
        "id": "oDzsxpONMR0A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}